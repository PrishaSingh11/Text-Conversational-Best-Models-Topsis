# -*- coding: utf-8 -*-
"""Text Conversational.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5jAUUbxHjAIhtkY-Lg7XdOOArNRgjUa
"""

# Function to validate weights and impacts
def validate_inputs(weights, impacts, num_criteria):
    if len(weights) != num_criteria or len(impacts) != num_criteria:
        raise ValueError("Weights and impacts must match the number of criteria.")
    if not all(i in ['+', '-'] for i in impacts):
        raise ValueError("Impacts must be '+' or '-'.")
    return weights, impacts

# Function to perform TOPSIS calculation
def calculate_topsis(decision_matrix, weights, impacts):
    # Step 1: Normalize the decision matrix
    normalized_matrix = decision_matrix / np.sqrt((decision_matrix ** 2).sum(axis=0))

    # Step 2: Weighted normalized decision matrix
    weighted_matrix = normalized_matrix * weights

    # Step 3: Determine ideal best and worst
    ideal_best = np.where(np.array(impacts) == '+', weighted_matrix.max(axis=0), weighted_matrix.min(axis=0))
    ideal_worst = np.where(np.array(impacts) == '+', weighted_matrix.min(axis=0), weighted_matrix.max(axis=0))

    # Step 4: Calculate distances from ideal best and worst
    dist_best = np.sqrt(((weighted_matrix - ideal_best) ** 2).sum(axis=1))
    dist_worst = np.sqrt(((weighted_matrix - ideal_worst) ** 2).sum(axis=1))

    # Step 5: Calculate TOPSIS score
    topsis_score = dist_worst / (dist_best + dist_worst)
    return topsis_score

# Load the CSV file
file_path = "llm_decision_matrix.csv"  # Path to the uploaded file
df = pd.read_csv(file_path)

# Display the decision matrix
print("Decision Matrix:")
display(df)

# Extract decision matrix (excluding model names)
decision_matrix = df.iloc[:, 1:].values  # Assuming first column is Model names
models = df.iloc[:, 0].tolist()          # Extract Model names

# Define weights and impacts
weights = [0.25, 0.20, 0.15, 0.15, 0.10, 0.10, 0.10]  # Modify as needed
impacts = ['-', '+', '+', '+', '-', '-', '+']        # Beneficial (+) and non-beneficial (-) criteria

# Validate inputs
weights, impacts = validate_inputs(weights, impacts, decision_matrix.shape[1])

# Apply TOPSIS
topsis_scores = calculate_topsis(decision_matrix, weights, impacts)

# Add TOPSIS scores and rankings to the DataFrame
df['Topsis Score'] = topsis_scores
df['Rank'] = df['Topsis Score'].rank(ascending=False).astype(int)

# Display final results
print("TOPSIS Results:")
display(df)

# Optional: Save the results to a CSV file
df.to_csv('topsis_results.csv', index=False)
print("Results saved to 'topsis_results.csv'")

# Sort the dataframe based on TOPSIS Score in descending order
df_sorted = df.sort_values("Topsis Score", ascending=False)

# Bar plot for TOPSIS Scores
plt.figure(figsize=(10, 6))
sns.barplot(x="Topsis Score", y="Model", data=df_sorted, palette="viridis")

plt.xlabel("TOPSIS Score")
plt.ylabel("Models")
plt.title("TOPSIS Final Scores for LLMs")

plt.show()

df_normalized = df.iloc[:, 1:-2].apply(lambda x: (x - x.min()) / (x.max() - x.min()))  # Normalize data

plt.figure(figsize=(10, 5))
sns.heatmap(df_normalized, annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Heatmap of Normalized Decision Matrix")
plt.show()

# Compute ideal and worst distances based on TOPSIS scores
ideal_distances = 1 - df["Topsis Score"]  # Inverse of the TOPSIS score
worst_distances = df["Topsis Score"]  # Directly using scores

plt.figure(figsize=(8, 5))
plt.scatter(ideal_distances, worst_distances, color="blue", s=100)

for i, model in enumerate(models):
    plt.text(ideal_distances.iloc[i] + 0.005, worst_distances.iloc[i], model, fontsize=12)

plt.xlabel("Distance from Ideal Solution (S*)")
plt.ylabel("Distance from Worst Solution (S‚Åª)")
plt.title("Scatter Plot of TOPSIS Distances")
plt.grid()
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x=df["Rank"], y=df["Model"], palette="coolwarm", order=df.sort_values("Rank")["Model"])
plt.xlabel("Rank")
plt.ylabel("Model")
plt.title("Final Ranking of LLMs (TOPSIS)")
plt.show()